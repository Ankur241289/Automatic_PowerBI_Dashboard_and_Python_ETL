{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9ce608-39a0-489f-9d53-0d767c83890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871714cb-f311-4685-8ae7-b86ad7374321",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Connecting to s3 bucket\n",
    "bucket = s3.Bucket('xetra-1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbd3dc3-f72b-487a-b119-fe2b65383c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inside the bucket there are a lot of folders, so we will connect to one of the with the name of foler as \"2022-01-03\"\n",
    "bucket_obj1 = bucket.objects.filter(Prefix= '2022-01-03')\n",
    "\n",
    "# We will create a 2nd bucket object as well so as to combine data available inside two buckets objects\n",
    "    \n",
    "    # Lets take the bucket object named \"2022-01-04\" so that when we combine data, we have 2 days worth of data combined in a single file.\n",
    "bucket_obj2 = bucket.objects.filter(Prefix = \"2022-01-04\")\n",
    "\n",
    "# Inside the bucket object again there are a lot of csv files, so we will create a variable with a list of all the files inside \"2022-01-03\"\n",
    "    # objects1 is for all the files inside bucket_obj1\n",
    "'''objects1 = [obj for obj in bucket_obj1]'''\n",
    "\n",
    "    # objects2 is for all the files inside bucket_obj2\n",
    "'''objects2 = [obj for obj in bucket_obj2]'''\n",
    "\n",
    "# Or we can directly concatanate the list of two objects together\n",
    "\n",
    "objects = [obj for obj in bucket_obj1] + [obj for obj in bucket_obj2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f8dc06-1f6d-4e1e-b1fd-bb083ba0a24f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR00.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR01.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR02.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR03.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR04.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR05.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR06.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR07.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR08.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR09.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR10.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR11.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR12.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR13.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR14.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR15.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR16.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR17.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR18.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR19.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR20.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR21.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR22.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-03/2022-01-03_BINS_XETR23.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR00.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR01.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR02.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR03.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR04.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR05.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR06.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR07.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR08.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR09.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR10.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR11.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR12.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR13.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR14.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR15.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR16.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR17.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR18.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR19.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR20.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR21.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR22.csv'),\n",
       " s3.ObjectSummary(bucket_name='xetra-1234', key='2022-01-04/2022-01-04_BINS_XETR23.csv')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether joining the two lists is successful or not\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b336ea-77ee-48b0-a3ef-c61838e2ff23",
   "metadata": {},
   "source": [
    "* we can see that \"objects\" now contains the list of all the files from date \"2022-01-03\" and \"2022-01-04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd3f01e-2cce-4b41-8db9-1e44adad5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets get a list of column names of the data\n",
    "csv_obj_init = bucket.Object(key = objects[0].key).get().get('Body').read().decode('utf-8')\n",
    "data_init = StringIO(csv_obj_init)\n",
    "df_init = pd.read_csv(data_init, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfcca639-bfe1-497a-a1e9-608c7c6fe80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ISIN', 'Mnemonic', 'SecurityDesc', 'SecurityType', 'Currency',\n",
       "       'SecurityID', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice',\n",
       "       'EndPrice', 'TradedVolume', 'NumberOfTrades'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chechking the culumn names in dataframe\n",
    "df_init.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "024b78f8-ad20-40e8-9b30-285d5b55c63a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n",
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_15680\\2990473283.py:9: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([df_merged, df], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Creating an empty pandas dataframe and fixing the column names as per our dataset\n",
    "df_merged = pd.DataFrame(columns=df_init.columns)\n",
    "\n",
    "# Merging the data present in all the csv files into a single merged Dataset called df_merged using a for loop\n",
    "for obj in objects:\n",
    "    csv_obj = bucket.Object(key=obj.key).get().get('Body').read().decode('utf-8')\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter=',')\n",
    "    df_merged = pd.concat([df_merged, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d94a592d-5115-4d20-a9c6-519527c3a3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>SecurityDesc</th>\n",
       "      <th>SecurityType</th>\n",
       "      <th>Currency</th>\n",
       "      <th>SecurityID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>StartPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>EndPrice</th>\n",
       "      <th>TradedVolume</th>\n",
       "      <th>NumberOfTrades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT0000A0E9W5</td>\n",
       "      <td>SANT</td>\n",
       "      <td>S+T AG O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504159</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>14.760</td>\n",
       "      <td>14.760</td>\n",
       "      <td>14.750</td>\n",
       "      <td>14.750</td>\n",
       "      <td>4414</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE000A0DJ6J9</td>\n",
       "      <td>S92</td>\n",
       "      <td>SMA SOLAR TECHNOL.AG</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504287</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>37.640</td>\n",
       "      <td>37.660</td>\n",
       "      <td>37.600</td>\n",
       "      <td>37.660</td>\n",
       "      <td>1649</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE000A0D6554</td>\n",
       "      <td>NDX1</td>\n",
       "      <td>NORDEX SE O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504290</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>13.990</td>\n",
       "      <td>14.030</td>\n",
       "      <td>13.940</td>\n",
       "      <td>13.960</td>\n",
       "      <td>23011</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE000A0D9PT0</td>\n",
       "      <td>MTX</td>\n",
       "      <td>MTU AERO ENGINES NA O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504297</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.050</td>\n",
       "      <td>179.500</td>\n",
       "      <td>179.500</td>\n",
       "      <td>2308</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE000A0HN5C6</td>\n",
       "      <td>DWNI</td>\n",
       "      <td>DEUTSCHE WOHNEN SE INH</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504314</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>2897</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239075</th>\n",
       "      <td>DE0007164600</td>\n",
       "      <td>SAP</td>\n",
       "      <td>SAP SE O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2505077</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:44</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>4000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239076</th>\n",
       "      <td>MT0000580101</td>\n",
       "      <td>M8G</td>\n",
       "      <td>MEDIA AND GAMES INV. EO 1</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2509636</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:44</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239077</th>\n",
       "      <td>DE000A0Z23Q5</td>\n",
       "      <td>ADN1</td>\n",
       "      <td>ADESSO SE  INH O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504440</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:45</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239078</th>\n",
       "      <td>DE000A3E5ES0</td>\n",
       "      <td>BIO0</td>\n",
       "      <td>BIOTEST AG ST O.N.Z.VERK.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>6973997</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>20:30</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239079</th>\n",
       "      <td>DE000A3E5ET8</td>\n",
       "      <td>BIO1</td>\n",
       "      <td>BIOTEST AG VZ O.N. Z.VERK</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>6973998</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>20:30</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239080 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ISIN Mnemonic               SecurityDesc  SecurityType  \\\n",
       "0       AT0000A0E9W5     SANT                S+T AG O.N.  Common stock   \n",
       "1       DE000A0DJ6J9      S92       SMA SOLAR TECHNOL.AG  Common stock   \n",
       "2       DE000A0D6554     NDX1             NORDEX SE O.N.  Common stock   \n",
       "3       DE000A0D9PT0      MTX   MTU AERO ENGINES NA O.N.  Common stock   \n",
       "4       DE000A0HN5C6     DWNI     DEUTSCHE WOHNEN SE INH  Common stock   \n",
       "...              ...      ...                        ...           ...   \n",
       "239075  DE0007164600      SAP                SAP SE O.N.  Common stock   \n",
       "239076  MT0000580101      M8G  MEDIA AND GAMES INV. EO 1  Common stock   \n",
       "239077  DE000A0Z23Q5     ADN1        ADESSO SE  INH O.N.  Common stock   \n",
       "239078  DE000A3E5ES0     BIO0  BIOTEST AG ST O.N.Z.VERK.  Common stock   \n",
       "239079  DE000A3E5ET8     BIO1  BIOTEST AG VZ O.N. Z.VERK  Common stock   \n",
       "\n",
       "       Currency SecurityID        Date   Time  StartPrice  MaxPrice  MinPrice  \\\n",
       "0           EUR    2504159  2022-01-03  08:00      14.760    14.760    14.750   \n",
       "1           EUR    2504287  2022-01-03  08:00      37.640    37.660    37.600   \n",
       "2           EUR    2504290  2022-01-03  08:00      13.990    14.030    13.940   \n",
       "3           EUR    2504297  2022-01-03  08:00     180.000   180.050   179.500   \n",
       "4           EUR    2504314  2022-01-03  08:00      37.280    37.280    37.280   \n",
       "...         ...        ...         ...    ...         ...       ...       ...   \n",
       "239075      EUR    2505077  2022-01-04  16:44     124.380   124.380   124.380   \n",
       "239076      EUR    2509636  2022-01-04  16:44       4.118     4.118     4.118   \n",
       "239077      EUR    2504440  2022-01-04  16:45     196.800   196.800   196.800   \n",
       "239078      EUR    6973997  2022-01-04  20:30      43.000    43.000    43.000   \n",
       "239079      EUR    6973998  2022-01-04  20:30      38.000    38.000    38.000   \n",
       "\n",
       "        EndPrice TradedVolume NumberOfTrades  \n",
       "0         14.750         4414              2  \n",
       "1         37.660         1649              3  \n",
       "2         13.960        23011             36  \n",
       "3        179.500         2308             22  \n",
       "4         37.280         2897              1  \n",
       "...          ...          ...            ...  \n",
       "239075   124.380         4000              3  \n",
       "239076     4.118           24              2  \n",
       "239077   196.800            7              2  \n",
       "239078    43.000            0              1  \n",
       "239079    38.000            0              1  \n",
       "\n",
       "[239080 rows x 14 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check our merged dataset\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765c627e-6507-4d74-95db-b533b28607a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are many columns which we do not need for further processing lets get rid of unwanted data\n",
    "columns_to_included = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice',\n",
    "       'EndPrice', 'TradedVolume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716db664-929e-43aa-83d8-a74d794bc6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>StartPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>EndPrice</th>\n",
       "      <th>TradedVolume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT0000A0E9W5</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>14.760</td>\n",
       "      <td>14.760</td>\n",
       "      <td>14.750</td>\n",
       "      <td>14.750</td>\n",
       "      <td>4414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE000A0DJ6J9</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>37.640</td>\n",
       "      <td>37.660</td>\n",
       "      <td>37.600</td>\n",
       "      <td>37.660</td>\n",
       "      <td>1649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE000A0D6554</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>13.990</td>\n",
       "      <td>14.030</td>\n",
       "      <td>13.940</td>\n",
       "      <td>13.960</td>\n",
       "      <td>23011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE000A0D9PT0</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>180.000</td>\n",
       "      <td>180.050</td>\n",
       "      <td>179.500</td>\n",
       "      <td>179.500</td>\n",
       "      <td>2308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE000A0HN5C6</td>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>08:00</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>37.280</td>\n",
       "      <td>2897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239075</th>\n",
       "      <td>DE0007164600</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:44</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>124.380</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239076</th>\n",
       "      <td>MT0000580101</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:44</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>4.118</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239077</th>\n",
       "      <td>DE000A0Z23Q5</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>16:45</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>196.800</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239078</th>\n",
       "      <td>DE000A3E5ES0</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>20:30</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>43.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239079</th>\n",
       "      <td>DE000A3E5ET8</td>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>20:30</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>239080 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ISIN        Date   Time  StartPrice  MaxPrice  MinPrice  \\\n",
       "0       AT0000A0E9W5  2022-01-03  08:00      14.760    14.760    14.750   \n",
       "1       DE000A0DJ6J9  2022-01-03  08:00      37.640    37.660    37.600   \n",
       "2       DE000A0D6554  2022-01-03  08:00      13.990    14.030    13.940   \n",
       "3       DE000A0D9PT0  2022-01-03  08:00     180.000   180.050   179.500   \n",
       "4       DE000A0HN5C6  2022-01-03  08:00      37.280    37.280    37.280   \n",
       "...              ...         ...    ...         ...       ...       ...   \n",
       "239075  DE0007164600  2022-01-04  16:44     124.380   124.380   124.380   \n",
       "239076  MT0000580101  2022-01-04  16:44       4.118     4.118     4.118   \n",
       "239077  DE000A0Z23Q5  2022-01-04  16:45     196.800   196.800   196.800   \n",
       "239078  DE000A3E5ES0  2022-01-04  20:30      43.000    43.000    43.000   \n",
       "239079  DE000A3E5ET8  2022-01-04  20:30      38.000    38.000    38.000   \n",
       "\n",
       "        EndPrice TradedVolume  \n",
       "0         14.750         4414  \n",
       "1         37.660         1649  \n",
       "2         13.960        23011  \n",
       "3        179.500         2308  \n",
       "4         37.280         2897  \n",
       "...          ...          ...  \n",
       "239075   124.380         4000  \n",
       "239076     4.118           24  \n",
       "239077   196.800            7  \n",
       "239078    43.000            0  \n",
       "239079    38.000            0  \n",
       "\n",
       "[239080 rows x 8 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering our merged dataframe to only those columns which we need for further process\n",
    "df_merged = df_merged.loc[:,columns_to_included]\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093bf04-2f6b-483d-b521-809a6457c9ec",
   "metadata": {},
   "source": [
    "* df_merged now containes only those columns which we need for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8199b90f-1275-478c-af59-e525fe83ab44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISIN            0\n",
       "Date            0\n",
       "Time            0\n",
       "StartPrice      0\n",
       "MaxPrice        0\n",
       "MinPrice        0\n",
       "EndPrice        0\n",
       "TradedVolume    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check our dataset for any Null Values\n",
    "df_merged.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bf6f1df-0c23-4e49-add6-cb9bbbd0c47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239080, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c4dab3-1655-459a-930a-8a5e2e3cdaba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
