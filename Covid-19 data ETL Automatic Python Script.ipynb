{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4794438",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "### 1. Global COVID-19 Overview:\n",
    "For this question, you would likely need columns related to global COVID-19 statistics, such as \"date,\" \"total_cases,\" \"total_deaths,\" and \"total_recovered.\"\n",
    "\n",
    "### 2. Regional Impact:\n",
    "To analyze regional impact, you would need columns that identify the region or country, such as \"location.\" You may also need columns like \"new_cases\" and \"new_deaths\" to calculate daily figures.\n",
    "\n",
    "### 3. Vaccination Progress:\n",
    "To track vaccination progress, you would need columns related to vaccine administration, such as \"total_vaccinations\" and \"people_vaccinated.\" The \"location\" column is also important for differentiating regions.\n",
    "\n",
    "### 4. Time Trends:\n",
    "Time trends analysis would require columns like \"date,\" \"new_cases,\" and \"new_deaths\" to show changes over time.\n",
    "\n",
    "### 5. Demographic Analysis:\n",
    "Demographic analysis might involve columns like \"age_group,\" \"gender,\" and \"total_cases\" or \"total_deaths\" broken down by these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd44eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries which will help us getting data from the web and store the same for further processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f16a812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data downloaded and saved as 'new_df'\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the CSV file\n",
    "url = \"https://covid.ourworldindata.org/data/owid-covid-data.csv\"\n",
    "\n",
    "# Send an HTTP GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Read the content of the response into a DataFrame\n",
    "    new_df = pd.read_csv(StringIO(response.text))\n",
    "    print(\"Data downloaded and saved as 'new_df'\")\n",
    "else:\n",
    "    print(\"Failed to download data\")\n",
    "#By importing StringIO from the io module and using it as shown in the corrected code, you should be able to read the CSV content from the HTTP response without encountering the attribute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "098af1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iso_code</th>\n",
       "      <th>continent</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>total_cases</th>\n",
       "      <th>new_cases</th>\n",
       "      <th>new_cases_smoothed</th>\n",
       "      <th>total_deaths</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smoothed</th>\n",
       "      <th>...</th>\n",
       "      <th>male_smokers</th>\n",
       "      <th>handwashing_facilities</th>\n",
       "      <th>hospital_beds_per_thousand</th>\n",
       "      <th>life_expectancy</th>\n",
       "      <th>human_development_index</th>\n",
       "      <th>population</th>\n",
       "      <th>excess_mortality_cumulative_absolute</th>\n",
       "      <th>excess_mortality_cumulative</th>\n",
       "      <th>excess_mortality</th>\n",
       "      <th>excess_mortality_cumulative_per_million</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.746</td>\n",
       "      <td>0.5</td>\n",
       "      <td>64.83</td>\n",
       "      <td>0.511</td>\n",
       "      <td>41128772.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341308</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023-09-09</td>\n",
       "      <td>265737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5717.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>16320539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341309</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023-09-10</td>\n",
       "      <td>265742.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>5718.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>16320539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341310</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023-09-11</td>\n",
       "      <td>265742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>5718.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>16320539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341311</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023-09-12</td>\n",
       "      <td>265742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>5718.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>16320539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341312</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>Africa</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>2023-09-13</td>\n",
       "      <td>265742.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714</td>\n",
       "      <td>5718.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143</td>\n",
       "      <td>...</td>\n",
       "      <td>30.7</td>\n",
       "      <td>36.791</td>\n",
       "      <td>1.7</td>\n",
       "      <td>61.49</td>\n",
       "      <td>0.571</td>\n",
       "      <td>16320539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>341313 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       iso_code continent     location        date  total_cases  new_cases  \\\n",
       "0           AFG      Asia  Afghanistan  2020-01-03          NaN        0.0   \n",
       "1           AFG      Asia  Afghanistan  2020-01-04          NaN        0.0   \n",
       "2           AFG      Asia  Afghanistan  2020-01-05          NaN        0.0   \n",
       "3           AFG      Asia  Afghanistan  2020-01-06          NaN        0.0   \n",
       "4           AFG      Asia  Afghanistan  2020-01-07          NaN        0.0   \n",
       "...         ...       ...          ...         ...          ...        ...   \n",
       "341308      ZWE    Africa     Zimbabwe  2023-09-09     265737.0        0.0   \n",
       "341309      ZWE    Africa     Zimbabwe  2023-09-10     265742.0        5.0   \n",
       "341310      ZWE    Africa     Zimbabwe  2023-09-11     265742.0        0.0   \n",
       "341311      ZWE    Africa     Zimbabwe  2023-09-12     265742.0        0.0   \n",
       "341312      ZWE    Africa     Zimbabwe  2023-09-13     265742.0        0.0   \n",
       "\n",
       "        new_cases_smoothed  total_deaths  new_deaths  new_deaths_smoothed  \\\n",
       "0                      NaN           NaN         0.0                  NaN   \n",
       "1                      NaN           NaN         0.0                  NaN   \n",
       "2                      NaN           NaN         0.0                  NaN   \n",
       "3                      NaN           NaN         0.0                  NaN   \n",
       "4                      NaN           NaN         0.0                  NaN   \n",
       "...                    ...           ...         ...                  ...   \n",
       "341308               0.000        5717.0         0.0                0.000   \n",
       "341309               0.714        5718.0         1.0                0.143   \n",
       "341310               0.714        5718.0         0.0                0.143   \n",
       "341311               0.714        5718.0         0.0                0.143   \n",
       "341312               0.714        5718.0         0.0                0.143   \n",
       "\n",
       "        ...  male_smokers  handwashing_facilities  hospital_beds_per_thousand  \\\n",
       "0       ...           NaN                  37.746                         0.5   \n",
       "1       ...           NaN                  37.746                         0.5   \n",
       "2       ...           NaN                  37.746                         0.5   \n",
       "3       ...           NaN                  37.746                         0.5   \n",
       "4       ...           NaN                  37.746                         0.5   \n",
       "...     ...           ...                     ...                         ...   \n",
       "341308  ...          30.7                  36.791                         1.7   \n",
       "341309  ...          30.7                  36.791                         1.7   \n",
       "341310  ...          30.7                  36.791                         1.7   \n",
       "341311  ...          30.7                  36.791                         1.7   \n",
       "341312  ...          30.7                  36.791                         1.7   \n",
       "\n",
       "        life_expectancy  human_development_index  population  \\\n",
       "0                 64.83                    0.511  41128772.0   \n",
       "1                 64.83                    0.511  41128772.0   \n",
       "2                 64.83                    0.511  41128772.0   \n",
       "3                 64.83                    0.511  41128772.0   \n",
       "4                 64.83                    0.511  41128772.0   \n",
       "...                 ...                      ...         ...   \n",
       "341308            61.49                    0.571  16320539.0   \n",
       "341309            61.49                    0.571  16320539.0   \n",
       "341310            61.49                    0.571  16320539.0   \n",
       "341311            61.49                    0.571  16320539.0   \n",
       "341312            61.49                    0.571  16320539.0   \n",
       "\n",
       "        excess_mortality_cumulative_absolute  excess_mortality_cumulative  \\\n",
       "0                                        NaN                          NaN   \n",
       "1                                        NaN                          NaN   \n",
       "2                                        NaN                          NaN   \n",
       "3                                        NaN                          NaN   \n",
       "4                                        NaN                          NaN   \n",
       "...                                      ...                          ...   \n",
       "341308                                   NaN                          NaN   \n",
       "341309                                   NaN                          NaN   \n",
       "341310                                   NaN                          NaN   \n",
       "341311                                   NaN                          NaN   \n",
       "341312                                   NaN                          NaN   \n",
       "\n",
       "        excess_mortality  excess_mortality_cumulative_per_million  \n",
       "0                    NaN                                      NaN  \n",
       "1                    NaN                                      NaN  \n",
       "2                    NaN                                      NaN  \n",
       "3                    NaN                                      NaN  \n",
       "4                    NaN                                      NaN  \n",
       "...                  ...                                      ...  \n",
       "341308               NaN                                      NaN  \n",
       "341309               NaN                                      NaN  \n",
       "341310               NaN                                      NaN  \n",
       "341311               NaN                                      NaN  \n",
       "341312               NaN                                      NaN  \n",
       "\n",
       "[341313 rows x 67 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "778e62db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 341313 entries, 0 to 341312\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   iso_code                                    341313 non-null  object \n",
      " 1   continent                                   325089 non-null  object \n",
      " 2   location                                    341313 non-null  object \n",
      " 3   date                                        341313 non-null  object \n",
      " 4   total_cases                                 303548 non-null  float64\n",
      " 5   new_cases                                   331893 non-null  float64\n",
      " 6   new_cases_smoothed                          330634 non-null  float64\n",
      " 7   total_deaths                                282171 non-null  float64\n",
      " 8   new_deaths                                  331938 non-null  float64\n",
      " 9   new_deaths_smoothed                         330708 non-null  float64\n",
      " 10  total_cases_per_million                     303548 non-null  float64\n",
      " 11  new_cases_per_million                       331893 non-null  float64\n",
      " 12  new_cases_smoothed_per_million              330634 non-null  float64\n",
      " 13  total_deaths_per_million                    282171 non-null  float64\n",
      " 14  new_deaths_per_million                      331938 non-null  float64\n",
      " 15  new_deaths_smoothed_per_million             330708 non-null  float64\n",
      " 16  reproduction_rate                           184817 non-null  float64\n",
      " 17  icu_patients                                37381 non-null   float64\n",
      " 18  icu_patients_per_million                    37381 non-null   float64\n",
      " 19  hosp_patients                               38499 non-null   float64\n",
      " 20  hosp_patients_per_million                   38499 non-null   float64\n",
      " 21  weekly_icu_admissions                       10087 non-null   float64\n",
      " 22  weekly_icu_admissions_per_million           10087 non-null   float64\n",
      " 23  weekly_hosp_admissions                      22980 non-null   float64\n",
      " 24  weekly_hosp_admissions_per_million          22980 non-null   float64\n",
      " 25  total_tests                                 79387 non-null   float64\n",
      " 26  new_tests                                   75403 non-null   float64\n",
      " 27  total_tests_per_thousand                    79387 non-null   float64\n",
      " 28  new_tests_per_thousand                      75403 non-null   float64\n",
      " 29  new_tests_smoothed                          103965 non-null  float64\n",
      " 30  new_tests_smoothed_per_thousand             103965 non-null  float64\n",
      " 31  positive_rate                               95927 non-null   float64\n",
      " 32  tests_per_case                              94348 non-null   float64\n",
      " 33  tests_units                                 106788 non-null  object \n",
      " 34  total_vaccinations                          78455 non-null   float64\n",
      " 35  people_vaccinated                           75095 non-null   float64\n",
      " 36  people_fully_vaccinated                     71728 non-null   float64\n",
      " 37  total_boosters                              46763 non-null   float64\n",
      " 38  new_vaccinations                            64590 non-null   float64\n",
      " 39  new_vaccinations_smoothed                   177948 non-null  float64\n",
      " 40  total_vaccinations_per_hundred              78455 non-null   float64\n",
      " 41  people_vaccinated_per_hundred               75095 non-null   float64\n",
      " 42  people_fully_vaccinated_per_hundred         71728 non-null   float64\n",
      " 43  total_boosters_per_hundred                  46763 non-null   float64\n",
      " 44  new_vaccinations_smoothed_per_million       177948 non-null  float64\n",
      " 45  new_people_vaccinated_smoothed              177631 non-null  float64\n",
      " 46  new_people_vaccinated_smoothed_per_hundred  177631 non-null  float64\n",
      " 47  stringency_index                            197651 non-null  float64\n",
      " 48  population_density                          289685 non-null  float64\n",
      " 49  median_age                                  269420 non-null  float64\n",
      " 50  aged_65_older                               259985 non-null  float64\n",
      " 51  aged_70_older                               266720 non-null  float64\n",
      " 52  gdp_per_capita                              264035 non-null  float64\n",
      " 53  extreme_poverty                             170123 non-null  float64\n",
      " 54  cardiovasc_death_rate                       264614 non-null  float64\n",
      " 55  diabetes_prevalence                         278090 non-null  float64\n",
      " 56  female_smokers                              198480 non-null  float64\n",
      " 57  male_smokers                                195780 non-null  float64\n",
      " 58  handwashing_facilities                      129611 non-null  float64\n",
      " 59  hospital_beds_per_thousand                  233580 non-null  float64\n",
      " 60  life_expectancy                             313970 non-null  float64\n",
      " 61  human_development_index                     256489 non-null  float64\n",
      " 62  population                                  341313 non-null  float64\n",
      " 63  excess_mortality_cumulative_absolute        11752 non-null   float64\n",
      " 64  excess_mortality_cumulative                 11752 non-null   float64\n",
      " 65  excess_mortality                            11752 non-null   float64\n",
      " 66  excess_mortality_cumulative_per_million     11752 non-null   float64\n",
      "dtypes: float64(62), object(5)\n",
      "memory usage: 174.5+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed1b291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['date'] = pd.to_datetime(new_df['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee316bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2020-01-03\n",
       "1        2020-01-04\n",
       "2        2020-01-05\n",
       "3        2020-01-06\n",
       "4        2020-01-07\n",
       "            ...    \n",
       "341308   2023-09-09\n",
       "341309   2023-09-10\n",
       "341310   2023-09-11\n",
       "341311   2023-09-12\n",
       "341312   2023-09-13\n",
       "Name: date, Length: 341313, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd9a769e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a list of columns which are not needed for our final dashboard\n",
    "columns_to_drop = ['iso_code',\n",
    " 'new_cases_smoothed',\n",
    " 'new_deaths',\n",
    " 'new_deaths_smoothed',\n",
    " 'total_cases_per_million',\n",
    " 'new_cases_per_million',\n",
    " 'new_cases_smoothed_per_million',\n",
    " 'total_deaths_per_million',\n",
    " 'new_deaths_per_million',\n",
    " 'new_deaths_smoothed_per_million',\n",
    " 'reproduction_rate',\n",
    " 'icu_patients_per_million',\n",
    " 'hosp_patients_per_million',\n",
    " 'weekly_icu_admissions',\n",
    " 'weekly_icu_admissions_per_million',\n",
    " 'weekly_hosp_admissions',\n",
    " 'weekly_hosp_admissions_per_million',\n",
    " 'total_tests_per_thousand',\n",
    " 'new_tests_per_thousand',\n",
    " 'new_tests_smoothed',\n",
    " 'new_tests_smoothed_per_thousand',\n",
    " 'tests_per_case',\n",
    " 'tests_units',\n",
    " 'new_vaccinations_smoothed',\n",
    " 'total_vaccinations_per_hundred',\n",
    " 'people_vaccinated_per_hundred',\n",
    " 'people_fully_vaccinated_per_hundred',\n",
    " 'total_boosters_per_hundred',\n",
    " 'new_vaccinations_smoothed_per_million',\n",
    " 'new_people_vaccinated_smoothed',\n",
    " 'new_people_vaccinated_smoothed_per_hundred',\n",
    " 'stringency_index',\n",
    " 'median_age',\n",
    " 'aged_65_older',\n",
    " 'aged_70_older',\n",
    " 'extreme_poverty',\n",
    " 'cardiovasc_death_rate',\n",
    " 'handwashing_facilities',\n",
    " 'hospital_beds_per_thousand',\n",
    " 'life_expectancy',\n",
    " 'human_development_index',\n",
    " 'excess_mortality_cumulative_absolute',\n",
    " 'excess_mortality_cumulative',\n",
    " 'excess_mortality',\n",
    " 'excess_mortality_cumulative_per_million']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2868bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns from out dataset\n",
    "new_df.drop(columns_to_drop,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3ea1f4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['continent', 'location', 'date', 'total_cases', 'new_cases',\n",
       "       'total_deaths', 'icu_patients', 'hosp_patients', 'total_tests',\n",
       "       'new_tests', 'positive_rate', 'total_vaccinations', 'people_vaccinated',\n",
       "       'people_fully_vaccinated', 'total_boosters', 'new_vaccinations',\n",
       "       'population_density', 'gdp_per_capita', 'diabetes_prevalence',\n",
       "       'female_smokers', 'male_smokers', 'population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check out the new remaining columns\n",
    "new_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af294030",
   "metadata": {},
   "source": [
    "* We will deal with the Null values in Microsoft Power Bi. So, lets save the data in a csv file which can be further connected to power bi for reports and dashboards generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33d7bdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "continent                   16224\n",
       "location                        0\n",
       "date                            0\n",
       "total_cases                 37765\n",
       "new_cases                    9420\n",
       "total_deaths                59142\n",
       "icu_patients               303932\n",
       "hosp_patients              302814\n",
       "total_tests                261926\n",
       "new_tests                  265910\n",
       "positive_rate              245386\n",
       "total_vaccinations         262858\n",
       "people_vaccinated          266218\n",
       "people_fully_vaccinated    269585\n",
       "total_boosters             294550\n",
       "new_vaccinations           276723\n",
       "population_density          51628\n",
       "gdp_per_capita              77278\n",
       "diabetes_prevalence         63223\n",
       "female_smokers             142833\n",
       "male_smokers               145533\n",
       "population                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the null values\n",
    "null_counts = new_df.isnull().sum()\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d6fdca",
   "metadata": {},
   "source": [
    "* Step 1 of Dealing with NUll : In all those columns where rows does not contain data which is the sum/aggregate of all previous rows (new_cases, new_tests), we will replace Null Values with zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "317463b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent                   16224\n",
      "location                        0\n",
      "date                            0\n",
      "total_cases                 37765\n",
      "new_cases                       0\n",
      "total_deaths                59142\n",
      "icu_patients                    0\n",
      "hosp_patients                   0\n",
      "total_tests                261926\n",
      "new_tests                       0\n",
      "positive_rate                   0\n",
      "total_vaccinations         262858\n",
      "people_vaccinated          266218\n",
      "people_fully_vaccinated    269585\n",
      "total_boosters             294550\n",
      "new_vaccinations                0\n",
      "population_density              0\n",
      "gdp_per_capita                  0\n",
      "diabetes_prevalence             0\n",
      "female_smokers                  0\n",
      "male_smokers                    0\n",
      "population                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying the columns where I want to replace NaN with zero\n",
    "columns_to_replace_with_zero = ['new_cases', 'icu_patients', 'hosp_patients', 'new_tests','positive_rate', 'new_vaccinations',\n",
    "                      'population_density','gdp_per_capita','diabetes_prevalence','female_smokers','male_smokers']\n",
    "# Creating a dictionary to specify replacement values for each column\n",
    "replacement_values = {col: 0 for col in columns_to_replace_with_zero}\n",
    "\n",
    "# Using the fillna method with the dictionary to replace NaN with zero in specific columns\n",
    "new_df.fillna(replacement_values, inplace=True)\n",
    "\n",
    "# creating a variable for new null counts affter transformation of data\n",
    "new_null_counts = new_df.isnull().sum()\n",
    "\n",
    "# Printing the resulting DataFrame\n",
    "print(new_null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f0fa29",
   "metadata": {},
   "source": [
    "* Step 2 of Dealing with NULL : In all those columns where rows contain data which is the sum/aggregate of all previous rows (total_cases, total_tests), we will replace Null Values with last available data. \n",
    "\n",
    "(For ex. if on date 15-09-2023 the value of total_cases for a particular country is 100000, and on date 16-09-2023 the value of total_cases is NULL, then we want this NULL value to be replaced with the value '100000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9c9c717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continent                  16224\n",
      "location                       0\n",
      "date                           0\n",
      "total_cases                    0\n",
      "new_cases                      0\n",
      "total_deaths                   0\n",
      "icu_patients                   0\n",
      "hosp_patients                  0\n",
      "total_tests                    0\n",
      "new_tests                      0\n",
      "positive_rate                  0\n",
      "total_vaccinations             0\n",
      "people_vaccinated              0\n",
      "people_fully_vaccinated        0\n",
      "total_boosters                 0\n",
      "new_vaccinations               0\n",
      "population_density             0\n",
      "gdp_per_capita                 0\n",
      "diabetes_prevalence            0\n",
      "female_smokers                 0\n",
      "male_smokers                   0\n",
      "population                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identifying the columns where you want to replace NaN with the most recent date's value with in the same location\n",
    "columns_to_replace_with_ffill = ['total_cases','total_deaths','total_tests','total_vaccinations','people_vaccinated',\n",
    "                                        'people_fully_vaccinated','total_boosters','population']\n",
    "\n",
    "# Sorting the DataFrame by date and location in descending order\n",
    "for col in columns_to_replace_with_ffill:\n",
    "    new_df[col].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Fill NaN values with 0 when no previous value is available within a location\n",
    "new_df[columns_to_replace_with_ffill] = new_df.groupby('location')[columns_to_replace_with_ffill].transform(lambda x: x.fillna(0))\n",
    "\n",
    "# Sort the DataFrame back to its original order\n",
    "new_df.sort_values(by=['location', 'date'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# creating variable to check sum of null value \n",
    "new_null_counts3 = new_df.isnull().sum()\n",
    "\n",
    "# Printing the resulting DataFrame\n",
    "print(new_null_counts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12372999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 341313 entries, 0 to 341312\n",
      "Data columns (total 22 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   continent                325089 non-null  object        \n",
      " 1   location                 341313 non-null  object        \n",
      " 2   date                     341313 non-null  datetime64[ns]\n",
      " 3   total_cases              341313 non-null  float64       \n",
      " 4   new_cases                341313 non-null  float64       \n",
      " 5   total_deaths             341313 non-null  float64       \n",
      " 6   icu_patients             341313 non-null  float64       \n",
      " 7   hosp_patients            341313 non-null  float64       \n",
      " 8   total_tests              341313 non-null  float64       \n",
      " 9   new_tests                341313 non-null  float64       \n",
      " 10  positive_rate            341313 non-null  float64       \n",
      " 11  total_vaccinations       341313 non-null  float64       \n",
      " 12  people_vaccinated        341313 non-null  float64       \n",
      " 13  people_fully_vaccinated  341313 non-null  float64       \n",
      " 14  total_boosters           341313 non-null  float64       \n",
      " 15  new_vaccinations         341313 non-null  float64       \n",
      " 16  population_density       341313 non-null  float64       \n",
      " 17  gdp_per_capita           341313 non-null  float64       \n",
      " 18  diabetes_prevalence      341313 non-null  float64       \n",
      " 19  female_smokers           341313 non-null  float64       \n",
      " 20  male_smokers             341313 non-null  float64       \n",
      " 21  population               341313 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(19), object(2)\n",
      "memory usage: 59.9+ MB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64a03035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: pyodbc in c:\\programdata\\anaconda3\\lib\\site-packages (4.0.34)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas sqlalchemy pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0b7a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "\n",
    "# Define the SQL Server connection details\n",
    "server = 'ANKUR_HP'       # Replace with your SQL Server instance name or IP address\n",
    "database = 'covid_19_dashboard_database'   # Replace with your database name\n",
    "\n",
    "# Create a connection string with Windows Authentication\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};Trusted_Connection=yes;'\n",
    "\n",
    "# Establish the database connection\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Replace 'your_table_name' with the desired table name\n",
    "table_name = 'table_for_covid_19_dashboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93892628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_for_covid_19_dashboard\n",
      "trace_xe_action_map\n",
      "trace_xe_event_map\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Establish the database connection\n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    \n",
    "    # Create a cursor\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Fetch the list of table names in the current database\n",
    "    table_names = cursor.tables(tableType='TABLE')\n",
    "    \n",
    "    # Print the list of table names\n",
    "    for table in table_names:\n",
    "        print(table.table_name)\n",
    "\n",
    "    # Close the cursor and the connection\n",
    "    #cursor.close()\n",
    "    #conn.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error: {str(e)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a5677c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame successfully saved to the table: table_for_covid_19_dashboard\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the SQL Server connection details\n",
    "server = 'ANKUR_HP'       # Replace with your SQL Server instance name or IP address\n",
    "database = 'covid_19_dashboard_database'   # Replace with your database name\n",
    "\n",
    "# Create a connection string with Windows Authentication\n",
    "conn_str = f'mssql+pyodbc://@{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server'\n",
    "\n",
    "# Create a database engine\n",
    "engine = create_engine(conn_str)\n",
    "\n",
    "# Replace 'your_table_name' with the desired table name\n",
    "table_name = 'table_for_covid_19_dashboard'\n",
    "\n",
    "try:\n",
    "    # Save the DataFrame to the SQL table using the SQLAlchemy engine\n",
    "    new_df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f'DataFrame successfully saved to the table: {table_name}')\n",
    "except Exception as e:\n",
    "    print(f'Error: {str(e)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
