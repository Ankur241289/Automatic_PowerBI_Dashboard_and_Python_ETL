{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b9ce608-39a0-489f-9d53-0d767c83890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script imports necessary libraries for data processing and AWS S3 interaction.\n",
    "\n",
    "- pandas (pd): Used for data manipulation and analysis.\n",
    "- numpy (np): Used for advanced numerical operations and arrays.\n",
    "- boto3: Provides an interface to interact with Amazon Web Services (AWS), including Amazon S3.\n",
    "- StringIO: A module for working with in-memory string buffers, often used for reading data from or writing data to strings.\n",
    "\"\"\"\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import StringIO, BytesIO\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a44570e-0869-4ba1-a6c3-7047c7d66986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapter Layer\n",
    "\n",
    "# 1. Reading data from source bucket and convert o pandas dataframe\n",
    "def read_csv_to_df (src_bucket, key, decoding = 'utf-8', seperater = ','):\n",
    "    csv_obj = src_bucket.Object(key=key).get().get('Body').read().decode(decoding)\n",
    "    data = StringIO(csv_obj)\n",
    "    df = pd.read_csv(data, delimiter = seperater)\n",
    "    return df\n",
    "\n",
    "# 2. Exporting data from merged dataframe to source bucket in the form of parquet file\n",
    "def write_df_to_s3(trg_bucket, df, key):\n",
    "    out_buffer = BytesIO()\n",
    "    df.to_parquet(out_buffer, index = False)\n",
    "    trg_bucket.put_object(Body = out_buffer.getvalue(), Key = key)\n",
    "    return True\n",
    "\n",
    "# Return list of files present for a particular date provided\n",
    "def list_files_in_prefix(bucket, prefix_date):\n",
    "    files = [obj.key for obj in bucket.objects.filter(Prefix = prefix_date)]\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6fa36f0-8a6a-4e80-bc21-af2e839bfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application layer\n",
    "\n",
    "# 1. Extracting data and merging it to a single merged datafranme\n",
    "def extract(src_bucket, date_list):\n",
    "    files = [key for date in date_list for key in list_files_in_prefix(src_bucket, date)]\n",
    "    df_merged = pd.concat([read_csv_to_df(src_bucket, obj) for obj in files], ignore_index = True)\n",
    "    return df_merged\n",
    "\n",
    "# 2. Data Transformation\n",
    "def transform_data1(df_merged, needed_columns, arg_date):\n",
    "    # Filtering the dataframe to onnly the needed columns\n",
    "    df_merged = df_merged.loc[:,needed_columns]\n",
    "\n",
    "    # Dropping the NUll values \n",
    "    df_merged.dropna(inplace =True)\n",
    "\n",
    "    # Creating a new column named 'opening_price'\n",
    "    df_merged['opening_price'] = df_merged.sort_values(['Time']).groupby(['ISIN', 'Date'])['StartPrice'].transform('first')\n",
    "\n",
    "    # Creating a new column named 'closing_price'\n",
    "    df_merged['closing_price'] = df_merged.sort_values(['Time']).groupby(['ISIN', 'Date'])['EndPrice'].transform('last')\n",
    "\n",
    "    # Aggregating the dataframe from hourly to daily data\n",
    "    df_merged = df_merged.groupby(['ISIN', 'Date'], as_index=False)\\\n",
    "                .agg(opening_price_eur=('opening_price', 'min'), \n",
    "                     closing_price_eur = ('closing_price', 'min'), \n",
    "                     mimimum_price_eur = ('MinPrice','min'), \n",
    "                     maximum_price_eur = ('MaxPrice','max'), \n",
    "                     daily_traded_volume =('TradedVolume','sum'))\n",
    "    \n",
    "    # creating a new column previous_closiong_price and assigning the value of closing_price_eur column of previous day\n",
    "    df_merged['previous_closing_price'] = df_merged.sort_values(['Date']).groupby(['ISIN'])['closing_price_eur'].shift(1)\n",
    "\n",
    "    # Calculating precent change from previous day's closing price\n",
    "    df_merged['change_in_closing_in_%'] = round((df_merged['closing_price_eur'] - df_merged['previous_closing_price'])\\\n",
    "                                                /df_merged['previous_closing_price']*100,2)\n",
    "\n",
    "    # Dropping column previous_closing_price as it is no longer needed\n",
    "    df_merged.drop(columns = ['previous_closing_price'], inplace = True)\n",
    "\n",
    "    # Lets round every number to upto two decimals\n",
    "    df_merged = df_merged.round(decimals = 2)\n",
    "\n",
    "    # returning the merged dataframe only after the given argumetn date\n",
    "    df_merged = df_merged[df_merged.Date >= arg_date]\n",
    "    return df_merged\n",
    "\n",
    "\n",
    "# 3. Load function\n",
    "def load_to_s3(trg_bucket, df_merged, target_key_format, target_file_format):\n",
    "    key = target_key_format + datetime.today().strftime(\"%Y%m%d_%H%M%S\") + target_file_format\n",
    "    write_df_to_s3(trg_bucket, df_merged , key)\n",
    "    return True\n",
    "\n",
    "def etl_report1(src_bucket, date_list, needed_columns, arg_date, trg_bucket, target_key_format, target_file_format):\n",
    "    df_merged = extract(src_bucket, date_list) # Using extract function to extract data to a dataframe\n",
    "    df_merged = transform_data1(df_merged, needed_columns, arg_date) # Transforming the data using transform function\n",
    "    load_to_s3(trg_bucket, df_merged, target_key_format, target_file_format) # Loading the transformed data to the target bucket\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5050139e-f24f-4bf4-9fb9-a29450e168d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application Layer ---- Not Core\n",
    "\n",
    "# 1. Return a list of all the dates from a given date till today (i.e the date code is run) in string format (== src_format)\n",
    "def return_date_list (arg_date,src_format):\n",
    "    min_date = datetime.strptime(arg_date, src_format).date() - timedelta(days =1)\n",
    "    todays_date = datetime.today().date()\n",
    "    date_list = [(min_date+timedelta(days =x)).strftime(src_format) for x in range ((todays_date - min_date).days+1)]\n",
    "    return date_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bff02da8-dd58-4e8a-975a-edc9b5028f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Main Function\n",
    "def main():\n",
    "    # listing necessary parameters/Configurations\n",
    "    # Later read config    \n",
    "    arg_date = '2022-12-25' # Setting an argument date from which we need data into our dataframe \"2022-12-25\" in our case      \n",
    "    src_format = '%Y-%m-%d'   # Setting source format of date     \n",
    "    src_bucket_name = 'xetra-1234' # setting source bucket name    \n",
    "    trg_bucket_name = 'xetra-1234-etl-target-bucket' # Setting target bucket   \n",
    "    # There are many columns which we do not need for further processing lets get rid of unwanted data\n",
    "    columns_to_included = ['ISIN', 'Date', 'Time', 'StartPrice', 'MaxPrice', 'MinPrice','EndPrice', 'TradedVolume'] \n",
    "    target_key_format = 'xetra_daily_report' # Describing the name of the key for output parquet file\n",
    "    target_file_format = '.parquet' # Describing target file format\n",
    "\n",
    "    # Init the connections\n",
    "    s3 = boto3.resource('s3')\n",
    "    src_bucket = s3.Bucket(src_bucket_name) # Connecting to source S3 bucket\n",
    "    trg_bucket = s3.Bucket(trg_bucket_name) # Connecting to target S3 bucket\n",
    "\n",
    "    # run application\n",
    "    date_list = return_date_list(arg_date, src_format)\n",
    "    etl_report1(src_bucket, date_list, columns_to_included, arg_date, trg_bucket, target_key_format, target_file_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2606a7e5-ca79-4966-ab10-abeed4eeccc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankur\\AppData\\Local\\Temp\\ipykernel_11204\\2947820405.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_merged = pd.concat([read_csv_to_df(src_bucket, obj) for obj in files], ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f9a34-5384-4462-8f6a-56b5d09075fc",
   "metadata": {},
   "source": [
    "### Reading the uploaded file to check whether the file content is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e74d546b-b8ec-4645-bf17-45746bb7d250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xetra_daily_report20231022_204256.parquet\n",
      "xetra_daily_report20231023_100331.parquet\n",
      "xetra_daily_report20231030_232951.parquet\n",
      "xetra_daily_report20231103_225752.parquet\n"
     ]
    }
   ],
   "source": [
    "trg_bucket_name = 'xetra-1234-etl-target-bucket'\n",
    "s3 = boto3.resource('s3')\n",
    "trg_bucket = s3.Bucket(trg_bucket_name)\n",
    "# reading the name of parquet file from S3 bucket\n",
    "for obj in trg_bucket.objects.all():\n",
    "    print (obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c1dcc-3c74-4e46-87e5-de3f250677ca",
   "metadata": {},
   "source": [
    "* Here we can see that Functional Implemantation of ETL Pipeline was successful and the new parquet file named\n",
    "  \"xetra_daily_report20231103_225752.parquet\" was created inside source bucket after successfull implementation of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dc37a277-5a79-4b7e-bf24-1da98d5aff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the S3 object ('prq_obj') from the specified S3 bucket ('bucket_target')\n",
    "# The object key is set to 'xetra_daily_report20231030_232951.parquet'\n",
    "# The object is retrieved from S3 and its body is read as bytes\n",
    "prq_obj = trg_bucket.Object(key='xetra_daily_report20231030_232951.parquet').get().get('Body').read()\n",
    "\n",
    "# Create a BytesIO object ('data') and load the Parquet data ('prq_obj') into it\n",
    "data = BytesIO(prq_obj)\n",
    "\n",
    "# Read the Parquet data from the BytesIO object into a pandas DataFrame ('df_report')\n",
    "df_report = pd.read_parquet(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2666d2f3-a4b2-4278-b968-52a28dcc868d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Date</th>\n",
       "      <th>opening_price_eur</th>\n",
       "      <th>closing_price_eur</th>\n",
       "      <th>mimimum_price_eur</th>\n",
       "      <th>maximum_price_eur</th>\n",
       "      <th>daily_traded_volume</th>\n",
       "      <th>change_in_closing_in_%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-25</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2864</td>\n",
       "      <td>4.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-26</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>36.10</td>\n",
       "      <td>37.70</td>\n",
       "      <td>2864</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>36.60</td>\n",
       "      <td>36.70</td>\n",
       "      <td>35.75</td>\n",
       "      <td>36.70</td>\n",
       "      <td>1773</td>\n",
       "      <td>-2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AT000000STR1</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>36.60</td>\n",
       "      <td>36.70</td>\n",
       "      <td>35.75</td>\n",
       "      <td>36.70</td>\n",
       "      <td>1773</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22364</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22365</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-28</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22366</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22367</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-30</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22368</th>\n",
       "      <td>XS2434891219</td>\n",
       "      <td>2022-12-31</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22369 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ISIN        Date  opening_price_eur  closing_price_eur  \\\n",
       "0      AT000000STR1  2022-12-25              36.10              37.70   \n",
       "1      AT000000STR1  2022-12-26              36.10              37.70   \n",
       "2      AT000000STR1  2022-12-27              36.10              37.70   \n",
       "3      AT000000STR1  2022-12-28              36.60              36.70   \n",
       "4      AT000000STR1  2022-12-29              36.60              36.70   \n",
       "...             ...         ...                ...                ...   \n",
       "22364  XS2434891219  2022-12-27               3.44               3.50   \n",
       "22365  XS2434891219  2022-12-28               3.44               3.66   \n",
       "22366  XS2434891219  2022-12-29               3.44               3.66   \n",
       "22367  XS2434891219  2022-12-30               3.44               3.66   \n",
       "22368  XS2434891219  2022-12-31               3.44               3.66   \n",
       "\n",
       "       mimimum_price_eur  maximum_price_eur  daily_traded_volume  \\\n",
       "0                  36.10              37.70                 2864   \n",
       "1                  36.10              37.70                 2864   \n",
       "2                  36.10              37.70                 2864   \n",
       "3                  35.75              36.70                 1773   \n",
       "4                  35.75              36.70                 1773   \n",
       "...                  ...                ...                  ...   \n",
       "22364               3.44               3.50                    0   \n",
       "22365               3.42               3.66                    0   \n",
       "22366               3.42               3.66                    0   \n",
       "22367               3.42               3.66                    0   \n",
       "22368               3.42               3.66                    0   \n",
       "\n",
       "       change_in_closing_in_%  \n",
       "0                        4.43  \n",
       "1                        0.00  \n",
       "2                        0.00  \n",
       "3                       -2.65  \n",
       "4                        0.00  \n",
       "...                       ...  \n",
       "22364                    0.00  \n",
       "22365                    4.53  \n",
       "22366                    0.00  \n",
       "22367                    0.00  \n",
       "22368                    0.00  \n",
       "\n",
       "[22369 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploaded data content is filfilling the business needs\n",
    "df_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b74985-53ca-4e73-b8a9-18dacc5a82c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
